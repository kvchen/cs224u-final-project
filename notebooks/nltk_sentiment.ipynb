{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elbert\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../datasets/CHUNK_RC_2018-02-28'\n",
    "SAVE_CLASSIFIER = '../datasets/nltk_sentiment_NBClassifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(DATASET_PATH, lines=True, chunksize=1e4).read()\n",
    "df = df[(df.body != '[deleted]') & (df.body != '[removed]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9229 210\n"
     ]
    }
   ],
   "source": [
    "all_comments = [(tokenize.word_tokenize(comment.body)+[str(comment.score)],\n",
    "                 comment.controversiality) for comment in df.itertuples()]\n",
    "\n",
    "no_contro = [comment for comment in all_comments if not comment[1]]\n",
    "contro = [comment for comment in all_comments if comment[1]]\n",
    "\n",
    "print(len(no_contro), len(contro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing = split_train_test(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentim_analyzer = SentimentAnalyzer()\n",
    "all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_feats(document, analyzer):\n",
    "    # document is list of words, where last element is score\n",
    "    vs = analyzer.polarity_scores(' '.join(document[:-1]))\n",
    "    return {k+'_VAD': v for k, v in vs.items()}\n",
    "\n",
    "sentim_analyzer.add_feat_extractor(vader_feats, analyzer=SentimentIntensityAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_feat(document):\n",
    "    return {'_score': document[-1]}\n",
    "\n",
    "sentim_analyzer.add_feat_extractor(score_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = sentim_analyzer.apply_features(training)\n",
    "test_set = sentim_analyzer.apply_features(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n",
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.9088983050847458\n",
      "F-measure [0]: 0.9522222222222222\n",
      "F-measure [1]: 0.022727272727272728\n",
      "Precision [0]: 0.9788692175899486\n",
      "Precision [1]: 0.014598540145985401\n",
      "Recall [0]: 0.9269875608436993\n",
      "Recall [1]: 0.05128205128205128\n"
     ]
    }
   ],
   "source": [
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)\n",
    "evaluate = sentim_analyzer.evaluate(test_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n",
      "Saving ../datasets/nltk_sentiment_NBClassifier\n",
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.6904761904761905\n",
      "F-measure [0]: 0.74\n",
      "F-measure [1]: 0.6176470588235294\n",
      "Precision [0]: 0.6981132075471698\n",
      "Precision [1]: 0.6774193548387096\n",
      "Recall [0]: 0.7872340425531915\n",
      "Recall [1]: 0.5675675675675675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# downsampling to fix imbalance\n",
    "no_contro_down = resample(no_contro, replace=False, n_samples=len(contro), random_state=123456)\n",
    "train_down, test_down = split_train_test(no_contro_down + contro)\n",
    "\n",
    "sa_down = SentimentAnalyzer()\n",
    "allneg_down = sa_down.all_words([mark_negation(doc) for doc in train_down])\n",
    "unifeats_down = sa_down.unigram_word_feats(allneg_down, min_freq=4)\n",
    "sa_down.add_feat_extractor(extract_unigram_feats, unigrams=unifeats_down)\n",
    "sa_down.add_feat_extractor(vader_feats, analyzer=SentimentIntensityAnalyzer())\n",
    "sa_down.add_feat_extractor(score_feat)\n",
    "\n",
    "trainset_down = sa_down.apply_features(train_down)\n",
    "testset_down = sa_down.apply_features(test_down)\n",
    "classifier_down = sa_down.train(trainer, trainset_down, save_classifier=SAVE_CLASSIFIER)\n",
    "evaluate_down = sa_down.evaluate(testset_down, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
