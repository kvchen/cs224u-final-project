{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../datasets/RC_2018-02-28') as infile, open('../datasets/CHUNK_RC_2018-02-28', 'w') as outfile:\n",
    "    for _ in range(10000):\n",
    "        outfile.write(infile.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '../datasets/CHUNK_RC_2018-02-28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(DATASET_PATH, lines=True, chunksize=1e4).read()\n",
    "df = df[(df.body != '[deleted]') & (df.body != '[removed]')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible sentiment features: SentiStrength, Vader-Sentiment, LIWC. Both SentiStrength and LIWC are proprietary. LIWC also can be used to give many different psychological and language dimensions (if only it weren't proprietary).\n",
    "\n",
    "TODO: learned Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vader_features(analyzer, body):\n",
    "    vs = analyzer.polarity_scores(body)\n",
    "    return {'vad_'+k: v for k, v in vs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readability features: word count, avg sentence length, avg word length, Gunning Fog, SMOG, Flesch-Kincaid. LIWC can give language features, but again is proprietary.\n",
    "\n",
    "TODO: COCA fluency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string, re\n",
    "from collections import Counter\n",
    "\n",
    "exclude = list(string.punctuation)\n",
    "\n",
    "def char_count(text):\n",
    "    text = text.replace(' ', '')\n",
    "    return len(text)\n",
    "\n",
    "def sentence_count(text):\n",
    "    ignoreCount = 0\n",
    "    sentences = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', text)\n",
    "    for sentence in sentences:\n",
    "        if not sentence:\n",
    "            ignoreCount += 1\n",
    "    return max(1, len(sentences) - ignoreCount)\n",
    "\n",
    "def read_features(body):\n",
    "    d = defaultdict(float)\n",
    "    cc = char_count(body)\n",
    "    sc = sentence_count(body)\n",
    "    words = ''.join(ch for ch in body if ch not in exclude).split()\n",
    "    d['WC'] = len(words)\n",
    "    d['SL'] = d['WC'] / sc\n",
    "    d['WL'] = cc / d['WC'] if d['WC'] > 0 else 0\n",
    "    type_count = Counter(words)\n",
    "    d['ttr'] = len(type_count) / float(sum(type_count.values())) if d['WC'] > 0 else 0\n",
    "#     d['GI'] = textstat.gunning_fog(body)\n",
    "#     d['SMOG'] = textstat.smog_index(body)\n",
    "#     d['FK'] = textstat.flesch_kincaid_grade(body)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_features(comment):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    body = comment.body\n",
    "    \n",
    "    features = {\n",
    "        'score': float(comment.score),\n",
    "    }\n",
    "    \n",
    "    features.update(vader_features(analyzer, body))\n",
    "    features.update(read_features(body))\n",
    "    \n",
    "    return pd.Series(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SL</th>\n",
       "      <th>WC</th>\n",
       "      <th>WL</th>\n",
       "      <th>score</th>\n",
       "      <th>ttr</th>\n",
       "      <th>vad_compound</th>\n",
       "      <th>vad_neg</th>\n",
       "      <th>vad_neu</th>\n",
       "      <th>vad_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.833333</td>\n",
       "      <td>249.0</td>\n",
       "      <td>4.578313</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.690763</td>\n",
       "      <td>0.6769</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.5171</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.588235</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7.884615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.9274</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.666667</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.605263</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.666667</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>-0.9175</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.428571</td>\n",
       "      <td>87.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.873563</td>\n",
       "      <td>0.7954</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.735294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.238095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22.666667</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.573529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>-0.2387</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.500000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.391304</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.3291</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.7574</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35.500000</td>\n",
       "      <td>142.0</td>\n",
       "      <td>5.035211</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.5422</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SL     WC        WL  score       ttr  vad_compound  vad_neg  \\\n",
       "0   13.833333  249.0  4.578313    3.0  0.690763        0.6769    0.127   \n",
       "1   20.000000   20.0  3.850000    2.0  0.950000        0.2500    0.098   \n",
       "2    9.000000   45.0  4.444444    1.0  0.888889        0.5171    0.035   \n",
       "3   10.000000   10.0  3.600000   85.0  1.000000        0.0000    0.000   \n",
       "4    4.588235   78.0  7.884615    1.0  0.923077        0.9274    0.000   \n",
       "5   12.666667   38.0  4.605263    5.0  0.973684        0.5574    0.074   \n",
       "6    6.666667   40.0  4.950000    1.0  0.875000       -0.9175    0.292   \n",
       "7   10.000000   30.0  4.633333    1.0  0.900000        0.7650    0.070   \n",
       "8   12.428571   87.0  5.000000    8.0  0.873563        0.7954    0.037   \n",
       "9   17.000000   34.0  4.735294    1.0  0.852941        0.8126    0.000   \n",
       "10  10.500000   21.0  4.238095    1.0  0.904762       -0.1027    0.168   \n",
       "11   2.500000    5.0  5.800000    1.0  1.000000        0.4199    0.000   \n",
       "12   1.000000    1.0  4.000000    3.0  1.000000        0.4215    0.000   \n",
       "13   1.000000    1.0  1.000000    1.0  1.000000        0.0000    0.000   \n",
       "14  22.666667   68.0  4.573529    1.0  0.852941       -0.2387    0.056   \n",
       "15  11.500000   23.0  4.391304   66.0  1.000000       -0.3291    0.105   \n",
       "16   3.000000    3.0  7.666667    9.0  0.666667        0.0000    0.000   \n",
       "17  11.000000   22.0  5.363636    4.0  0.954545        0.7574    0.000   \n",
       "18   9.000000    9.0  4.444444   -6.0  1.000000        0.4404    0.000   \n",
       "20  35.500000  142.0  5.035211   18.0  0.704225        0.5422    0.125   \n",
       "\n",
       "    vad_neu  vad_pos  \n",
       "0     0.733    0.139  \n",
       "1     0.714    0.188  \n",
       "2     0.819    0.147  \n",
       "3     1.000    0.000  \n",
       "4     0.843    0.157  \n",
       "5     0.766    0.160  \n",
       "6     0.614    0.094  \n",
       "7     0.698    0.233  \n",
       "8     0.848    0.115  \n",
       "9     0.749    0.251  \n",
       "10    0.680    0.152  \n",
       "11    0.589    0.411  \n",
       "12    0.000    1.000  \n",
       "13    0.000    0.000  \n",
       "14    0.918    0.026  \n",
       "15    0.895    0.000  \n",
       "16    1.000    0.000  \n",
       "17    0.724    0.276  \n",
       "18    0.734    0.266  \n",
       "20    0.729    0.146  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "featurized = df.iloc[:20].apply(all_features, axis=1)\n",
    "\n",
    "with pd.option_context('display.max_colwidth', 500, 'display.max_columns', 100):\n",
    "    display(featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featurized = df.apply(all_features, axis=1).to_dict('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: featurize each comment, make list of dicts, use sklearn.feature_extraction.DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.94438559322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "v = DictVectorizer(sparse=False)\n",
    "\n",
    "v.fit(featurized.values())\n",
    "X = v.transform(featurized.values())\n",
    "y = df['controversiality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "model = gnb.fit(X_train, y_train)\n",
    "print('Score:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversample Score: 0.546316359697\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_resample, y_resample = SMOTE().fit_sample(X, y)\n",
    "X_retrain, X_retest, y_retrain, y_retest = train_test_split(X_resample, y_resample, test_size=0.2)\n",
    "gnb_re = GaussianNB()\n",
    "model_re = gnb_re.fit(X_retrain, y_retrain)\n",
    "print('Oversample Score:', model_re.score(X_retest, y_retest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
