{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_SUBREDDITS = {'worldnews'}\n",
    "INVALID_BODY_CONTENT = ['[removed]', '[deleted]', 'i am a bot']\n",
    "\n",
    "\n",
    "def is_valid(comment):\n",
    "    for invalid_content in INVALID_BODY_CONTENT:\n",
    "        if invalid_content.lower() in comment['body'].lower():\n",
    "            return False\n",
    "    \n",
    "    return comment['subreddit'] in VALID_SUBREDDITS\n",
    "\n",
    "def is_controversial(comment):\n",
    "    return comment['controversiality'] > 0\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "def preprocess_comment(comment):\n",
    "    filters = {        \n",
    "        # Markdown filters\n",
    "        r\"\\[([^\\[]+)\\]\\(([^\\)]+)\\)\": \"\\1\",  # [urls]()\n",
    "        r\"(\\*\\*|__)(.*?)\\1\": \"\\2\",          # **bold** text\n",
    "        r\"(\\*|_)(.*?)\\1\": \"\\2\",             # __italicized__ text\n",
    "\n",
    "        # Get rid of URLs\n",
    "        r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\": \"\",\n",
    "        \n",
    "        # Reddit-specific\n",
    "        r\"\\/?u\\/[A-Za-z0-9_-]+\": \" __user_token__ \",\n",
    "        r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\": \" __number_token__ \",\n",
    "        \n",
    "        # Split all by slash\n",
    "        r\"\\/\": \" / \",\n",
    "    }\n",
    "    \n",
    "    comment = comment['body']\n",
    "    for f, sub in filters.items():\n",
    "        comment = re.sub(f, sub, comment)\n",
    "    \n",
    "    comment = comment.lower()\n",
    "    \n",
    "    tokenized = nltk.tokenize.word_tokenize(comment)\n",
    "    return ' '.join(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data_path, train_path, test_path):\n",
    "    with open(f\"{train_path}.c\", 'w') as train_c, \\\n",
    "         open(f\"{train_path}.nc\", 'w') as train_nc, \\\n",
    "         open(f\"{test_path}.c\", 'w') as test_c, \\\n",
    "         open(f\"{test_path}.nc\", 'w') as test_nc:\n",
    "        \n",
    "        outfiles = {\n",
    "            'train': {\n",
    "                'c': train_c,\n",
    "                'nc': train_nc,\n",
    "            },\n",
    "            'test': {\n",
    "                'c': test_c,\n",
    "                'nc': test_nc,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(data_path, 'r') as infile:\n",
    "            for idx, line in enumerate(infile):\n",
    "                comment = json.loads(line)\n",
    "\n",
    "                if not is_valid(comment):\n",
    "                    continue\n",
    "                \n",
    "                # Maintain a roughly even train/test split\n",
    "                split = 'train' if idx % 2 else 'test'\n",
    "                controversial = 'c' if is_controversial(comment) else 'nc'\n",
    "                \n",
    "                preprocessed = preprocess_comment(comment)\n",
    "                if not preprocessed:\n",
    "                    continue\n",
    "                \n",
    "                outfile = outfiles[split][controversial]\n",
    "                print(preprocessed, file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split('../datasets/RC_2018-03', '../datasets/train', '../datasets/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
